# Быстрая справка для отчета

## Где что находится

### 1. Листинги ядер CUDA

**Naive ядро:**
- **Файл:** `transpose_cuda.cu`
- **Строки:** 6-17
- **Имя функции:** `transpose_naive_kernel`

**Shared Memory ядро:**
- **Файл:** `transpose_cuda.cu`
- **Строки:** 20-60
- **Имя функции:** `transpose_shared_kernel`

### 2. Вычисление блоков и потоков

**Naive версия:**
- **Файл:** `transpose_cuda.cu`
- **Строки:** 95-106
- **Функция:** `transpose_gpu_naive`
- **Формула:**
  ```c
  TILE_SIZE = 32
  blockSize = (32, 32)  // 1024 потока
  gridX = (cols + 32 - 1) / 32
  gridY = (rows + 32 - 1) / 32
  ```

**Shared Memory версия:**
- **Файл:** `transpose_cuda.cu`
- **Строки:** 183-188
- **Функция:** `transpose_gpu_shared`
- **Формула:**
  ```c
  TILE_DIM = 32
  BLOCK_ROWS = 8
  dimBlock = (32, 8)  // 256 потоков
  gridX = (cols + 32 - 1) / 32
  gridY = (rows + 32 - 1) / 32
  ```

### 3. CPU реализация

- **Файл:** `transpose_cpu.c`
- **Строки:** 3-9
- **Алгоритм:** Двойной цикл O(rows × cols)

### 4. Основная программа

- **Файл:** `main.c`
- **Строки:** 1-140
- **Функции:**
  - Инициализация тестов (строки 14-17)
  - Цикл по размерам (строки 38-130)
  - Измерение времени CPU (строки 60-67)
  - Измерение времени GPU naive (строки 70-80)
  - Измерение времени GPU shared (строки 83-93)

### 5. Графики

**Данные:**
- **Файл:** `results.csv`
- **Формат:** CSV с колонками: size, cpu_time_ms, gpu_naive_time_ms, gpu_shared_time_ms, speedup_naive, speedup_shared, correct

**Скрипт построения:**
- **Файл:** `plot_results.py`
- **Результат:** `transpose_plot.png` (создается после запуска)

**Запуск:**
```bash
python plot_results.py
```

---

## Алгоритм работы (кратко)

### Naive версия:
1. Каждый поток обрабатывает один элемент матрицы
2. Поток (row, col) читает `in[row][col]` и пишет в `out[col][row]`
3. Прямой доступ к глобальной памяти

### Shared Memory версия:
1. Матрица разбивается на тайлы 32×32
2. Блок потоков (32×8 = 256 потоков) читает тайл в shared memory
3. Синхронизация (`__syncthreads()`)
4. Транспонирование в shared memory (меняем индексы)
5. Запись транспонированного тайла в глобальную память

**Ключевое отличие:** Shared memory версия использует быструю локальную память и коалесцированный доступ, что дает значительное ускорение.

---

## Формулы для отчета

### Количество потоков в блоке:
- **Naive:** `TILE_SIZE² = 32² = 1024 потока`
- **Shared:** `TILE_DIM × BLOCK_ROWS = 32 × 8 = 256 потоков`

### Количество блоков:
- **По X:** `⌈cols / TILE_SIZE⌉ = (cols + TILE_SIZE - 1) / TILE_SIZE`
- **По Y:** `⌈rows / TILE_SIZE⌉ = (rows + TILE_SIZE - 1) / TILE_SIZE`

### Всего потоков:
- **Naive:** `gridX × gridY × 1024`
- **Shared:** `gridX × gridY × 256`

### Пример для матрицы 1000×1000:
- Блоков: `⌈1000/32⌉ = 32` по каждой оси → 32×32 = 1024 блока
- Потоков (naive): 1024 × 1024 = 1,048,576
- Потоков (shared): 1024 × 256 = 262,144

---

## Что включить в отчет

### Обязательно:
1. ✅ Листинг `transpose_naive_kernel` (строки 6-17)
2. ✅ Листинг `transpose_shared_kernel` (строки 20-60)
3. ✅ Описание алгоритма с иллюстрациями
4. ✅ Формулы вычисления блоков и потоков
5. ✅ График из `transpose_plot.png`
6. ✅ Листинг `main.c`
7. ✅ Листинг `transpose_cpu.c`
8. ✅ Листинг `transpose_cuda.cu` (или ключевые части)

### Рекомендуется:
- Таблица результатов из `results.csv`
- Анализ ускорения для разных размеров
- Объяснение преимуществ shared memory подхода

